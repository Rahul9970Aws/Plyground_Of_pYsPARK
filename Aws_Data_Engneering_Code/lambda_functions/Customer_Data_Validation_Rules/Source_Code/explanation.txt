âœ… 1. Main Script (Lambda Function Entrypoint)
File: (main lambda file â€” let's call it lambda_function.py)
Key Functions:

main(bucket_name, file_path, logger)

lambda_handler(event, context)

Responsibilities:

Triggered via AWS Lambda.

Reads CSV from S3.

Creates a pandas DataFrame.

Calls DataValidator to validate records.

Calls database_connection() and inserts valid records.

Saves invalid records to S3.

Calls get_email_templete() to send a summary email.

Dependencies:

DataValidator (from generic_validator.py)

database_connection, insert_records, shutdown_connection (from generic_db_function.py)

upload_df_to_s3, get_email_templete (from aws_utility.py)

âœ… 2. Data Validation Logic
File: generic_validator.py
Class: DataValidator
Responsibilities:

Takes a pandas DataFrame and validates:

customer_id: Must be positive int

full_name: Letters and spaces only

email: Valid email pattern

age: Between 1 and 120

date_of_birth: Past date, year > 1900

phone_number: 10-digit number

Mandatory fields are not null

Duplicate check on full_name + date_of_birth

age matches date_of_birth

Returns two DataFrames:

valid_df (passes all checks)

invalid_df (fails one or more)

âœ… 3. Database Operations
File: generic_db_function.py
Key Functions:

database_connection(logger)

Reads DB creds from AWS SSM Parameter Store

Returns a secure DB connection (PostgreSQL via pg8000)

insert_records(df, connection, logger)

Inserts each row of valid data into dim_customer

Ignores duplicates via ON CONFLICT

shutdown_connection(logger)

Gracefully closes DB connection

âœ… 4. AWS Utility Functions
File: aws_utility.py
Functions:

upload_df_to_s3(df, bucket_name, file_key, logger)

Uploads a pandas DataFrame as a CSV into S3.

get_email_templete(lambda_name, s3_file_path, total_count, valid_count, invalid_count, logger)

Prepares and sends an HTML+plain-text email report using Amazon SES.

Includes:

Function name

Timestamp

Record counts

Link to the invalid records file on S3

send_email_ses(...)

Sends the actual email using Amazon SES.

------------------------------------------------------------------------------------------

1. Lambda is triggered â†’ `lambda_handler` runs
2. Reads CSV file from S3
3. Converts to pandas DataFrame
4. DataFrame passed to `DataValidator` â†’ returns valid_df, invalid_df
5. Valid records:
     â†’ `insert_records()` â†’ written to PostgreSQL via `pg8000`
6. Invalid records:
     â†’ `upload_df_to_s3()` â†’ uploaded to S3 under /Curoupt_Records/...
7. Summary Email:
     â†’ `get_email_templete()` â†’ generates + sends email via SES
8. DB connection closed
9. Lambda returns JSON summary of results
----------------------------------------------------------------------------------------------
Suggestions for Improvement (Optional)

Chunked DB Insertion:

For large datasets, consider batch inserts using executemany() or bulk COPY operations.

Validation Logging Enhancements:

Add summary of what kinds of validations failed most (e.g. most common column failure).

Retry Logic for AWS Services:

Wrap S3/SES/SSM calls with retry decorators or exponential backoff.

Add Tests:

Unit tests for validators and S3/database functions using pytest and moto.

Country Validation:

Uncomment and use the validate_country() method if needed.
----------------------------------------------------------------------------------------------------

ğŸ” END-TO-END SYSTEM OVERVIEW

This is a data validation pipeline for customer records that runs inside an AWS Lambda function. The pipeline:

Ingests customer data from S3 (CSV file).

Validates records using a custom validation class.

Saves valid records to a PostgreSQL database.

Uploads invalid records back to S3.

Sends a summary report email using Amazon SES.

Everything is modular, with each file handling a specific job.

ğŸ“ MODULE 1: lambda_function.py â€” ORCHESTRATOR (MAIN)
ğŸ”§ Purpose:

Entry point for the entire pipeline

Triggered as an AWS Lambda function

Coordinates all modules (S3, validation, DB, email)

ğŸ” Key Functions:
âœ… main(bucket_name, file_path, logger)

Reads the CSV from S3

Converts it to a pandas DataFrame

Passes the DataFrame to DataValidator

Establishes DB connection

Inserts valid records to DB

Returns both valid and invalid records

âœ… lambda_handler(event, context)

AWS Lambda handler

Defines S3 paths and filenames

Calls main()

Uploads invalid records to S3

Triggers email notification

ğŸ§© Dependencies:

generic_validator.py â†’ for DataValidator

generic_db_function.py â†’ DB connection & insert

aws_utility.py â†’ Upload to S3 + send email

ğŸ“ MODULE 2: generic_validator.py â€” DATA QUALITY CHECKER
ğŸ”§ Purpose:

Performs data quality checks on the customer records using pandas.

âœ… Class: DataValidator
ğŸ” Validations Done:
Field	Validation Logic
customer_id	Must be an integer > 0
full_name	Only alphabetic characters and spaces (^[A-Za-z ]+$)
email	Matches common email format using regex
age	Integer between 1 and 120
date_of_birth	Must be a valid past date after year 1900
phone_number	Must be exactly 10 digits
not_null	Ensures all key fields are not null
no_duplicates	No duplicates based on full_name + date_of_birth
age_consistency	Validates that the given age matches the calculated age from DOB
ğŸ” Method: run_all_validations()

Applies each validation above

Combines results into a DataFrame

Filters and returns:

valid_df (all validations passed)

invalid_df (one or more failed)

ğŸ“ MODULE 3: generic_db_function.py â€” DATABASE LAYER
ğŸ”§ Purpose:

Handles all interactions with a PostgreSQL database (using pg8000)

ğŸ” Functions:
âœ… database_connection(logger)

Fetches DB credentials from AWS SSM Parameter Store (/store/db-credentials/db-config)

Uses boto3 to get a securely encrypted JSON config

Establishes a PostgreSQL connection

âœ… insert_records(df, connection, logger)

Loops through each row in valid_df

Uses pg8000.native.Connection.run() to insert into dim_customer

Uses ON CONFLICT (customer_id) DO NOTHING to avoid duplicates

âœ… shutdown_connection(logger)

Closes the DB connection safely

ğŸ“ MODULE 4: aws_utility.py â€” AWS HELPERS
ğŸ”§ Purpose:

Contains helper functions to work with S3 and SES email notifications

âœ… upload_df_to_s3(df, bucket_name, file_key, logger)

Converts a DataFrame into a CSV (in memory using StringIO)

Uploads it to the target path in Amazon S3

âœ… get_email_templete(...)

Constructs a report email showing:

Lambda function name

Execution time

Total / valid / invalid record counts

Link to corrupt record file in S3

Calls send_email_ses() to deliver it

âœ… send_email_ses(...)

Sends email via Amazon SES

Supports both text and HTML formats

Requires verified sender (from_email)

You can configure recipients (to_email)

ğŸ§  SYSTEM FLOW: STEP-BY-STEP EXPLAINED

Hereâ€™s what happens when the Lambda function is triggered:

âœ… 1. File is read from S3

File path: customer-data-validation-bkt/customer_data_validation.csv

Data is converted to a pandas DataFrame

âœ… 2. Validations are applied

Runs all 9 checks (including regex, type checks, cross-field logic)

Results split into:

valid_df

invalid_df

âœ… 3. Valid records are inserted into PostgreSQL

Only if customer_id is not already there (thanks to ON CONFLICT)

âœ… 4. Invalid records are uploaded to S3

Stored at path:
s3://data-engineering-generic-bkt/Curoupt_Records/Customer/<date>/Customer_invalid_records.csv

âœ… 5. Summary email is sent

Email includes:

Function name

Total / valid / invalid counts

S3 path to corrupt file

Sent via SES to a fixed recipient

ğŸ” Security Considerations
Component	Secured By
DB Credentials	AWS SSM Parameter Store (with encryption)
File Access	S3 Bucket Policies / IAM Roles
Email	Amazon SES (Verified email required)
âœ… SAMPLE EMAIL OUTPUT

Subject: Lambda customer-validator - Data Validation Report

Lambda Function: customer-validator
Execution Time: 2025-08-20 12:10:34 UTC
Total Records: 1000
Valid Records: 950 (95%)
Invalid Records: 50 (5%)
Corrupt file stored at: s3://.../Customer_invalid_records.csv


HTML version also includes a neat table with clickable S3 link.

ğŸ§¾ Summary Table of Responsibilities
Module/File	Responsibility
lambda_function.py	Orchestrates full ETL and validation pipeline
generic_validator.py	Validates records using business rules
generic_db_function.py	Connects to DB and inserts valid records
aws_utility.py	Uploads invalid data to S3, sends email via SES
ğŸš€ Optional Enhancements You Can Add
Feature	Description
âœ… Lambda Timeout & Memory Tuning	Ensure Lambda has enough time and memory to process large CSVs
âœ… Retry Policies	Add retries for SES, S3, and DB operations
âœ… DLQ (Dead Letter Queue)	Capture Lambda failures in SQS for future analysis
âœ… Country Validation	Currently commented out â€” enable for stricter checks
âœ… Error Logging to CloudWatch	Already using logger, but consider structured logs or pushing to centralized log service
âœ… Alerts via SNS	If > X% records are invalid, send critical alert via SNS
